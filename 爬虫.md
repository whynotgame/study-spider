çˆ¬è™«

â€‹    ç›®çš„ï¼šè·å–ç½‘é¡µæ•°æ®



â€‹    1.è·å–ä¸€ä¸ªç½‘é¡µæ•°æ®ç”¨

â€‹    urllib.request.urlopen()    #æ‹¬å·å†…æ˜¯ç½‘é¡µurl

â€‹    è·å–ç½‘é¡µæ•°æ®

â€‹    è¡¥å……:urlopenæ˜¯ä½¿ç”¨getæ–¹æ³•è¯·æ±‚ç½‘é¡µçš„



â€‹    2.æˆ‘ä»¬æŠŠè·å–çš„ä¸œè¥¿èµ‹å€¼ç»™response    [*è¿™ä¸ªresponseå¯ä»¥æ˜¯ä»»ä½•ï¼Œåæ­£åªæ˜¯ä¼ å€¼ï¼Œæ¯”å¦‚p=urllib.request.urlopen()ä¹Ÿå¯ä»¥*]

â€‹    response=urllib.request.urlopen()

â€‹    æŠŠç½‘é¡µæ•°æ®ç»™äº†response



â€‹    3.è¾“å‡ºè¿™ä¸ªæ•°æ®ç”¨

â€‹    print(response.read().decode('utf-8'))    [*read()æ–¹æ³•ä¸çŸ¥é“æ˜¯æ€ä¹ˆæ¥çš„ï¼Œä½†ä¸ç†ä»–è¿™æ ·å°±èƒ½è¯»*;*ä¸ºäº†è®©è¿™ä¸ªæ•°æ®ç¼–ç è¾“å‡ºæ˜¯ä¸­å›½å­—ï¼Œåœ¨åé¢å¤šåŠ ä¸€ä¸ªæ–¹æ³• decode('utf-8')*]

â€‹    è¾“å‡ºç½‘é¡µæ•°æ®

   

å®Œæ•´ä»£ç     [è·å–ç™¾åº¦çš„ç½‘é¡µä»£ç ]

![image-20230411165134635](C:\Users\xiaoming\AppData\Roaming\Typora\typora-user-images\image-20230411165134635.png)





2023.4.14



â€‹    å­¦ä¹ è‡ªå·±åˆ›å»ºhadler





â€‹    é—®é¢˜1ï¼šæœ‰æŠ¥é”™ é—®é¢˜ä¸çŸ¥

urllib.error.URLError: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)>



   è§£å†³é—®é¢˜ï¼š å…³é—­sslè®¤è¯

```
import ssl
ssl._create_default_https_context = ssl._create_unverified_context
```



ä¿å­˜cookie

ä½¿ç”¨cookie

  1.å…ˆåˆ›å»ºä¸€ä¸ªcookie

  2.åˆ›å»ºä¸€ä¸ªhandler

  3.åˆ›å»ºä¸€ä¸ªopener

  4.ä½¿ç”¨è¿™ä¸ªopener

  ç»“æœæœ‰å¯èƒ½æ˜¯æ•°ç»„ï¼Œä¹Ÿå¯èƒ½ç›´æ¥è¯»å‡º



åˆ¤æ–­errorç±»å‹

 1.urlerror å¥½åƒæ˜¯ä¸‡èƒ½çš„

 2.httperroræ˜¯urlerrorçš„å­ç±»



è§£æurlå†…å®¹

ä½¿ç”¨urlparseï¼ˆä¸èƒ½ç›´æ¥è°ƒç”¨ï¼Œå¾—ä½¿ç”¨urllib.parse importå‡ºæ¥ï¼‰

schemeæ˜¯åè®®ï¼Œnetlocæ˜¯åŸŸåï¼Œpathæ˜¯è·¯å¾„ï¼Œparamsæ˜¯å‚æ•°ï¼Œqueryæ˜¯æŸ¥è¯¢æ¡ä»¶ï¼Œfragmentæ˜¯é”šç‚¹

â€‹                                     å‰/                 /å                 ;å                         ?å                            #å



æ„é€ urlå†…å®¹

ä½¿ç”¨æ•°æ®ç»“æ„é•¿åº¦å¿…é¡»ä¸º6ï¼ˆåªèƒ½ä¸º6ï¼Œä½†æ˜¯å†…å®¹å¯ä»¥ä¸ºç©ºï¼‰ï¼Œæ•°æ®ç»“æ„å¯ä»¥æ˜¯å…ƒç»„(*)ï¼Œåˆ—è¡¨[*]ï¼Œ

é›†åˆä¸è¡Œï¼Œå¥½åƒä¸èƒ½è·å–ã€‚å­—å…¸å¯ä»¥ï¼Œä½†åªè·å–äº†key

ä¸ºä»€ä¹ˆè¦æ„é€ urlï¼Œè¿™é‡Œçš„æ–¹æ³•ä¸æ˜¯è¿æ¥ä¸¤ä¸ªæˆ–è€…å¤šä¸ªå­—ç¬¦ä¸²å—ï¼Ÿï¼Ÿ



urljoinæ›´å¥½ï¼Œå®ƒå¯å¯¹ç¼ºå¤±çš„éƒ¨åˆ†è‡ªåŠ¨è¡¥å……ï¼Œè¡¥å……çš„å†…å®¹ä¸ç¬¬ä¸€ä¸ªå‚æ•°æ²¡å•¥å…³ç³»

1.ä½¿ç”¨æ—¶è¦æ³¨æ„å‚æ•°éƒ½è¦ä½¿ç”¨httpsåè®®ï¼Œè¦ä¹ˆä¸€ä¸ªç”¨ä¸€ä¸ªä¸ç”¨ï¼Œè¦ä¹ˆä¸¤ä¸ªéƒ½æ˜¯httpsåè®®

2.å®ƒæ˜¯æ ¹æ®ç¬¬äºŒä¸ªå‚æ•°è¿›è¡Œä¿®æ”¹çš„ï¼Œç¬¬äºŒä¸ªå‚æ•°ä¿®æ”¹çš„ä¸€å¥æ˜¯æŒ‰ç…§ç¬¬ä¸€ä¸ªå‚æ•°æ¥çš„ï¼Œç¼ºä»€ä¹ˆè¡¥ä»€ä¹ˆï¼Œéƒ½æœ‰å°±ä½¿ç”¨ç¬¬äºŒä¸ª

3.æˆ‘åªèƒ½è¯´æ²¡æœ‰åŠ å·å¥½ç”¨



urlæ›´åƒæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå¯ä»¥éšæ„åŠ è¿›å»



urlencodeå¯ä»¥æŠŠå­—å…¸è½¬ä¸ºå¸¦æœ‰**â€˜&â€˜**ç¬¦å·çš„å­—ç¬¦ä¸²

```
params = {
    'name':'jack',
    'age':16
}
```

è½¬ä¸º  name=jack&age=16 

å†…æ¶µ<class 'dict'>è½¬ä¸º<class 'str'>



parse_qs

æŠŠname=jack&age=16 è½¬ä¸º

params = {
    'name':'jack',
    'age':16
}

**å­—å…¸ä½¿ç”¨ params['name']**



parse_qsl

æŠŠname=jack&age=16 è½¬ä¸º

[('name', 'jack'), ('age', '16')]



åœ¨urlä¸­åŠ ç‚¹ä¸­æ–‡å¯èƒ½å¯¼è‡´é—®é¢˜

ä½¿ç”¨quoteè½¬ä¸ºurlè®¤è¯†çš„å…¶ä»–å­—ç¬¦



åœ¨urlä¸­å‘ç°ä¸€äº›å¥‡æ€ªçš„ç©æ„

ä½¿ç”¨unquoteæˆ–è®¸èƒ½è¿˜åŸ



robots

ä¸ºä»€ä¹ˆå¯ä»¥åŒæ—¶å­˜åœ¨ä¸¤ä¸ªuser-agentå’Œdisallowï¼Œåº”å½“ç›¸ä¿¡å“ªä¸€ ä¸ª

è§£å†³æ–¹æ³•ï¼Œæ¯ä¸€ä¸ªçˆ¬å–çš„urléƒ½ç»è¿‡  urllibçš„robotparserçš„RobotFileParserçš„can_fetchï¼Œå»éªŒè¯èƒ½å¦çˆ¬å–

 æ–¹æ³•: å…ˆå¾—åˆ°çˆ¬å–ç½‘ç«™çš„robotsåè®®ï¼Œå†è§£æè¿™ä¸ªrobotsåè®®(ä½¿ç”¨parse)ï¼Œå†åˆ¤æ–­èƒ½å¦çˆ¬å–ç½‘ç«™(ä½¿ç”¨can_fetch)



**requestsåº“**

è¿™ä¸ªä¸œè¥¿æ¯”ä¸Šé¢å¥½ç”¨å¤šäº†

1.requests.getæ–¹æ³•åŠ å…¥å‚æ•°paramsï¼Œä¸ç”¨åœ¨urlåé¢åŠ é—®å·(?)

é—®é¢˜:ä¸çŸ¥é“æ€ä¹ˆé˜…è¯»ç½‘é¡µçš„æ–¹æ³•



çˆ¬å–å‡ºç°é—®é¢˜

requests.exceptions.SSLError: HTTPSConnectionPool(host='ssr1.scrape.center', port=443): Max retries exceeded with url: / (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:992)')))

è¯´æ˜¯SSLé—®é¢˜

ä½¿ç”¨requestsåº“æ–¹æ³•çš„getæ–¹æ³•

è§£å†³ï¼Œä½¿ç”¨getæ–¹æ³•é‡Œçš„

```
verify=False
```

åè¿˜æœ‰ä¸€ç‚¹é—®é¢˜

warnings.warn(

è§£å†³æ–¹æ³•:

```
import urllib3

urllib3.disable_warnings()
```

å®Œæˆï¼Œä¸è¿‡é‚£ä¸ªå¥½åƒæ˜¯è‡ªæ¬ºæ¬ºäººçš„æ–¹å¼ï¼Œä½†æ˜¯çœ‹èµ·æ¥å¥½



çˆ¬å–å›¾ç‰‡

çˆ¬å–å›¾ç‰‡åªèƒ½è·å–å…¶äºŒè¿›åˆ¶æ•°æ®ï¼Œè¦æƒ³çœ‹åˆ°å›¾ç‰‡è¦æŠŠäºŒè¿›åˆ¶æ•°æ®è¯»å–

ä½¿ç”¨withå¤„ç†æ–‡ä»¶å¯¹è±¡(è¯´æ›´å¥½ï¼Œä½†æˆ‘æ²¡è§‰å¾—)

```
with open('favicon.ico','wb') as f:
    f.write(r.content)
    
    2.è§£æ³•
    ***=open()
    ***.wirte()
```

as åªèƒ½åœ¨import with exceptåé¢ä½¿ç”¨

f.rwiteæ˜¯ä½¿ç”¨å¯¹è±¡æ–¹æ³•    r.contentæ˜¯æ•°æ®å†…å®¹

wbè¡¨ç¤ºäºŒè¿›åˆ¶å†™ï¼Œä¸å­˜åœ¨å°±åˆ›å»ºï¼Œå­˜åœ¨å°±è¦†ç›–(å‚è€ƒ:https://www.runoob.com/python/python-func-open.html)

è¯»å–icoæ–‡ä»¶å†è¯»å‡ºæ¥å¥½åƒåªèƒ½ä»¥icoæ–‡ä»¶ç»“å°¾è¯»å‡º



session

ä¸¤æ¬¡getç½‘é¡µï¼Œæœ€æ–°çš„ä¼šè¦†ç›–æ‰ä¹‹å‰çš„ä¸€ä¸ªï¼Œå°±åƒæ˜¯åˆæ‰“å¼€äº†ä¸€ä¸ªç½‘é¡µ

sessionä½¿ç”¨éœ€è¦å…ˆåˆ›å»ºä¸€ä¸ªsessionå¯¹è±¡    s = requests.Session()ï¼Œç„¶åä¸¤æ¬¡getå‘ç°ï¼Œæ²¡æœ‰ç›¸åŒåç¼€çš„ï¼Œä¼šè¡¥ä¸Šï¼Œå³ä¸¤ä¸ªä¿¡æ¯ä¸€åŒå‡ºç°ã€‚æœ‰ç›¸åŒåç¼€çš„ï¼Œä¼šåä¸€ä¸ªè¦†ç›–å‰ä¸€ä¸ª

è¦†ç›–:

```
s.get('https://www.httpbin.org/cookies/set/number/112233')
r = s.get('https://www.httpbin.org/cookies/set/number/123456789')
```

è¡¥ä¸Š:

```
s.get('https://www.httpbin.org/cookies/set/name/112233')
r = s.get('https://www.httpbin.org/cookies/set/number/123456789')
```

æ„Ÿè§‰ä¸Šå°±æ˜¯ï¼Œç‚¹å¼€äº†ç½‘é¡µå†…ä¸€ä¸ªç½‘é¡µï¼Œå®ƒä¿å­˜äº†ä½ ä¹‹å‰ç½‘é¡µç•™ä¸‹çš„ä¿¡æ¯



sslï¼ˆéªŒè¯ï¼‰

æ–‡ä»¶å‘½åä¸èƒ½ä¸ºssl.py ï¼ˆä¸çŸ¥é“ä¸ºä»€ä¹ˆï¼‰

getå†…éƒ¨å¯ä»¥åŠ ä¸€ä¸ªvertify å«ä¹‰æ˜¯ä¸è¦å»éªŒè¯è¯ä¹¦äº†ï¼Œä½†æ˜¯å®ƒä¼šå†è®©ä½ ç»™å®ƒæŒ‡å®šè¯ä¹¦ï¼Œçœ‹èµ·æ¥åƒæŠ¥é”™

```
from requests.packages import urllib3

urllib3.disable_warnings()
```

åŠ å…¥ä»¥ä¸Šä»£ç ï¼Œå°±å¯ä»¥å¿½ç•¥è¿™ä¸ªè­¦å‘Šäº†

è¿˜å¯ä»¥æ•è·æ—¥å¿—ï¼ŒæŒ‡å®šæ–‡ä»¶ä½œä¸ºå®¢æˆ·ç«¯è¯ä¹¦ï¼ˆæ•è·æ—¥å¿—ä¸çŸ¥é“åœ¨å“ªçœ‹ã€‚æ²¡æœ‰æ–‡ä»¶æ˜¯è¯ä¹¦ï¼‰



timeout

åœ¨getæ–¹æ³•ä¸­ï¼Œå¯ä»¥è®¾ç½®timeoutï¼Œå«ä¹‰æ˜¯è¶…æ—¶æˆ‘å°±æŠ¥é”™ã€‚æ—¶é—´åŒ…æ‹¬ä¸¤ä¸ªé˜¶æ®µ,è¿æ¥å’Œè¯»å–ï¼ˆæ ¹æœ¬ä¸èƒ½åˆ†è¾¨è¿™ä¸¤ä¸ªé˜¶æ®µï¼‰,ä¸åŠ è¿™ä¸ªå‚æ•°ï¼Œé»˜è®¤æ˜¯æ°¸ä¹…ç­‰å¾…ï¼ˆè¿™æ ·å°±ä¼šå¡æ­»åœ¨è¿™ä¸ªæ­¥å­ä¸Šï¼Œå»ºè®®åŠ timeoutï¼‰



èº«ä»½è®¤è¯

requests.getå¯ä»¥ç›´æ¥è®¾ç½®èº«ä»½è®¤è¯æ‰€éœ€çš„å†…å®¹ï¼Œåœ¨åé¢åŠ auth(authç¿»è¯‘è®¤è¯)

```
r = requests.get('https://ssr3.scrape.center/',auth=('admin','admin'))
```

requestsè¿˜æœ‰å…¶ä»–è®¤è¯æ–¹å¼ï¼Œæ¯”å¦‚OAuth1,HTTPBasicAuthï¼Œä½†æ˜¯çœ‹ä¸æ‡‚æœ‰ä»€ä¹ˆåŒºåˆ«,OAuthå¥½åƒæœ‰ç‚¹ä¸œè¥¿è—ç€

OAuth ä¸æ˜¯ä¸€ä¸ªAPIæˆ–è€…æœåŠ¡ï¼Œè€Œæ˜¯ä¸€ä¸ªéªŒè¯æˆæƒ(Authorization)çš„å¼€æ”¾æ ‡å‡†ï¼ˆå‚è€ƒç½‘ç«™[OAuth2.0 è¯¦è§£ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/89020647)ï¼‰



proxies(ä»£ç†) 

proxyä¹Ÿæ˜¯ä»£ç†

æˆ‘çŒœå¯èƒ½æ˜¯ä¸è¦ç”¨ä¸€ä¸ªåœ°å€é¢‘ç¹çš„è¯·æ±‚ä¸€ä¸ªç½‘ç«™ï¼Œä¸ºäº†è¿™ä¸ªç›®çš„å‡ºç°çš„ä»£ç†

åœ¨ç½‘ä¸ŠæŸ¥åˆ°ä¸€ä¸ªä»£ç†ç½‘ç«™([ğŸ¤– Free Proxy List [1,184 IPs Online\] (geonode.com)](https://geonode.com/free-proxy-list))å¥½åƒåªèƒ½ç”¨socksè¿›è¡Œä»£ç†

ä½¿ç”¨ä¹‹åæŠ¥é”™ï¼ˆç”±äºç›®æ ‡è®¡ç®—æœºç§¯ææ‹’ç»ï¼Œæ— æ³•è¿æ¥ï¼‰ï¼Œç½‘ä¸Šä¸€èˆ¬æ˜¯è‡ªå·±å»ºç½‘ç«™ç„¶åä»£ç†ï¼Œæ‰€ä»¥èƒ½è§£å†³ã€‚ä½†æ˜¯æˆ‘ç”¨ç½‘ä¸Šç»™çš„ä»£ç†ç½‘ç«™è¿›è¡Œç™»å½•ï¼Œå°±æ˜¯ç”¨ä¸äº†

è¿˜æœ‰ï¼Œä»£ç†çš„æ„ä¹‰ä¸æ˜ç¡®ï¼Œå³ä¸çŸ¥é“ä»–çš„æµé€šè¿‡ç¨‹ï¼Œä¸çŸ¥é“å“ªä¸€æ­¥æœ‰é—®é¢˜ è§£å†³([pythonæ„å»ºIPä»£ç†æ± ï¼ˆProxy Poolï¼‰[é€šä¿—æ˜“æ‡‚\]-è…¾è®¯äº‘å¼€å‘è€…ç¤¾åŒº-è…¾è®¯äº‘ (tencent.com)](https://cloud.tencent.com/developer/article/2087761))

æˆ‘å‘ç»™ä»£ç†ï¼Œä»£ç†ç»™ç›®æ ‡ï¼Œç›®æ ‡ç»™ä»£ç†ï¼Œä»£ç†ç»™æˆ‘

æˆåŠŸï¼Œå°±æ˜¯é‚£ä¸ªç ´ç½‘ç«™ä¸è¡Œï¼Œæˆ–è€…socks5ä¸ä¼šç”¨

httpså¯ä»¥ä¸å¡«ï¼Œä¹Ÿå¯ä»¥å®ç°ä»£ç†



è‡ªå·±æ„é€ requestsæ–¹æ³•ï¼ˆprepareï¼šå‡†å¤‡ï¼‰

é¦–å…ˆå¼•å…¥ä¸€ä¸ªRequestså¯¹è±¡ï¼ˆfrom requests import Requestï¼‰ï¼Œæ”¾å…¥å¯¹åº”æ•°æ®ï¼ˆ'POST',url,data=...,headers=...ï¼‰,å†è°ƒç”¨Sessionä¸­çš„prepare_requestsæ–¹æ³•è½¬æ¢ä¸ºä¸€ä¸ªå¯¹è±¡ï¼ˆæ ¹æœ¬ä¸çŸ¥é“ä¸ºä»€ä¹ˆè½¬æ¢ï¼‰,ç„¶åä½¿ç”¨sessionä¸­çš„sendæ–¹æ³•æŠŠè¿™ä¸ªè½¬æ¢åçš„å¯¹è±¡å‘é€è¿‡å»ï¼Œå°±å¯ä»¥æ¥å—åˆ°ä¿¡æ¯äº†

1.ä¸ºä»€ä¹ˆä¸€å®šè¦ä½¿ç”¨session

2.æ„é€ å¯¹è±¡æ”¾å…¥æ•°æ®æˆ‘å¯ä»¥ç†è§£ï¼Œä¸ºä»€ä¹ˆè¦æŠŠå®ƒè½¬æ¢ä¸ºä¸€ä¸ªä¸çŸ¥é“å¹²å•¥ç”¨çš„å¯¹è±¡(å³ä¸çŸ¥é“sessionä¸­çš„prepare_requestsåˆ°åº•å¹²å•¥)

æ„é€ requestsæ–¹æ³•æ€è·¯:ç”¨session.sendæ–¹æ³•æŠŠæ•°æ®å‘åˆ°æŒ‡å®šç½‘ç«™ï¼Œæ•°æ®çš„æ ¼å¼è¦æ±‚è¦ç”¨prepare_requestsè½¬æ¢ï¼Œæ•°æ®çš„å†…å®¹ç”±è‡ªå·±å®šä¹‰ã€‚ï¼ˆä¸getï¼Œpostæ–¹æ³•ä¸€æ ·ï¼Œå¯ä»¥å†™data,headersåœ¨é‡Œï¼‰



æ­£åˆ™è¡¨è¾¾å¼æµ‹è¯•

æ–‡æœ¬ï¼šHello,my phone number is 010-4165456165 and email is wocai@445566.com, and my website is https://www.woshishei.com

æ–¹æ³•ï¼šä½¿ç”¨re.match(A,B)ï¼Œç¬¬ä¸€ä¸ªå†…å®¹å†™æ­£åˆ™è¡¨è¾¾å¼ï¼Œç¬¬äºŒä¸ªå†…å®¹å†™éœ€è¦æ­£åˆ™è¡¨è¾¾å¼åˆ†è§£çš„å†…å®¹

è¾“å‡ºç»“æœæ˜¯ç”¨matchä¹‹åçš„ç»“æœ.group()ä¸€ä¸‹å¾—åˆ°çš„

åœ¨æ­£åˆ™è¡¨è¾¾å¼å†…ï¼Œå¯ä»¥å°†æƒ³è¦çš„ç»“æœä½¿ç”¨ï¼ˆï¼‰æ‹¬èµ·æ¥ã€‚ç„¶ååœ¨è¾“å‡ºæ—¶ï¼Œåœ¨.group()çš„æ‹¬å·å†…åŠ å…¥1ï¼Œ2...æ¥è·å–æ‰€éœ€è¦çš„æ•°æ®



é€šç”¨åŒ¹é…

æ­£åˆ™è¡¨è¾¾å¼å†…åŠ å…¥.*è¡¨ç¤ºä»»æ„å…¨éƒ¨åŒ¹é…ï¼Œå¯ä»¥ç›´æ¥å…¨éƒ¨åŒ¹é…

^Hè¡¨ç¤ºä»¥Hå¼€å¤´çš„ï¼Œç»“æœåªåŒ¹é…ä¸€ä¸ªå­—ç¬¦"H"

m$è¡¨ç¤ºä»¥mç»“å°¾çš„ï¼Œä½†æ˜¯ä¸èƒ½åªå•å•ä½¿ç”¨è¿™ä¸ªåŒ¹é…ï¼Œä¸çŸ¥é“ä¸ºä»€ä¹ˆ

```
result = re.match('o$',content)
```

ï¼ˆä¸Šé¢çš„æ˜¯é”™çš„ï¼‰ï¼Œä¸çŸ¥é“é”™çš„åŸå› 



è´ªå©ªä¸éè´ªå©ª

æ­£åˆ™è¡¨è¾¾å¼ï¼Œ.*ä»£è¡¨å…¨éƒ¨åŒ¹é…ï¼Œä½†æ˜¯ä¼šå°½å¯èƒ½çš„åŒ¹é…ï¼Œä¸()ä½¿ç”¨ï¼Œè¿˜ä¼šç•™ä¸‹ä¸€ä¸ª

.*?æ˜¯å°½å¯èƒ½å°‘çš„åŒ¹é…,ä¸()ä½¿ç”¨ï¼Œå°½å¯èƒ½ä¸åŒ¹é…

```
result = re.match('.*?(\d+)',content)
```

ä¸Šé¢å°±æ˜¯å°½å¯èƒ½åœ¨ä¸æ˜¯æ•°å­—å‰å°‘åŒ¹é…ï¼Œæ‰€ä»¥ä¸€åˆ°æ•°å­—å°±åœæ­¢

```
result = re.match('.*(\d+)',content)
```

è¿™ä¸ªæ˜¯å°½å¯èƒ½åœ¨æ•°å­—å‰åŒ¹é…ï¼Œæ‰€ä»¥åªç•™ä¸‹ä¸€ä¸ªæ•°å­—



ä¿®é¥°ç¬¦ (ä¿®é¥°æ­£åˆ™è¡¨è¾¾å¼çš„åŒ¹é…å†…å®¹ï¼Œæ¯”å¦‚ä¸åŒ¹é…è¿™ä¸ªï¼ŒåŒ¹é…é‚£ä¸ª)

åœ¨æ­£åˆ™è¡¨è¾¾å¼ä¸­ï¼Œé¦–å…ˆæ˜¯åŒ¹é…åˆ°å­—ç¬¦ä¸²å…¨éƒ¨ï¼ˆæ„æ€æ˜¯å¦‚æœä¸åˆ°æœ€åé‚£ä¸ªâ€˜â€™â€˜æ˜¯ä¸èƒ½ç”¨ç»“å°¾å­—ç¬¦çš„ï¼‰ã€‚ç„¶åä½¿ç”¨æ¢è¡Œç¬¦ï¼Œæ­£åˆ™è¡¨è¾¾å¼ä¸åŒ¹é…æ¢è¡Œå­—ç¬¦ã€‚è¦æƒ³è®©æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ¢è¡Œå­—ç¬¦ï¼Œéœ€è¦æ·»åŠ ä¿®é¥°ç¬¦re.S



è½¬ä¹‰å­—ç¬¦

re.matchä½¿ç”¨ï¼Œ(A,B),Aæ˜¯åŒ¹é…å†…å®¹ï¼Œå¯ä»¥ç›´æ¥æ˜¯Bï¼Œä¹Ÿå¯ä»¥æŒ‘Bå†…çš„ä¸œè¥¿ï¼Œç”¨å­—ç¬¦æ›¿ä»£ã€‚Bæ˜¯è¦åŒ¹é…çš„å†…å®¹

å½“è¦åŒ¹é…çš„å†…å®¹æœ‰ä¸æ›¿ä»£å­—ç¬¦ç›¸åŒçš„å†…å®¹ï¼Œç”¨\å»è½¬ä¹‰è¿™ä¸ªå­—ç¬¦



searchæ–¹æ³•ï¼ˆæŸ¥åˆ°å°±è¿”å›ï¼‰

matchæ–¹æ³•ï¼šæ˜¯ä»å¤´å¼€å§‹åŒ¹é…ï¼Œå¦‚æœæ²¡æœ‰å°±è¿”å›None

searchæ–¹æ³•ï¼šæ˜¯è¯¶ä¸ªæŸ¥ï¼ŒæŸ¥åˆ°ç¬¬ä¸€ä¸ªå°±è¿”å›åŒ¹é…å†…å®¹ï¼Œå…¨éƒ¨æŸ¥å®Œæ²¡æœ‰æ‰è¿”å›None

æ­£åˆ™è¡¨è¾¾å¼ä½¿ç”¨çš„æ—¶å€™å°½é‡è¡¨ç¤ºåˆ°ç²¾ç¡®ä¸€ç‚¹çš„ä½ç½®

```
result = re.search('.*?singer=(.*?)>',content,re.S)
```

ä¸Šé¢æ­£åˆ™è¡¨è¾¾å¼è¡¨ç¤ºï¼Œåœ¨contentå†…å®¹ä¸­æ‰¾ å°½é‡å°‘çš„å†…å®¹ï¼Œä»¥singer=å¼€å¤´çš„ï¼Œå°½é‡å°‘çš„å†…å®¹ï¼Œä»¥>ç»“å°¾ï¼Œå¿½ç•¥å›è½¦å­—ç¬¦

```
result = re.search('.*?singer=(.*)>',content,re.S)
```

è¿™ä¸ªæ­£åˆ™è¡¨è¾¾å¼è¡¨ç¤ºï¼Œæ‰¾å°½é‡å°‘çš„ï¼Œä»¥singerå¼€å¤´çš„ï¼Œå°½é‡å¤šçš„å†…å®¹ï¼Œä»¥>ç»“å°¾çš„

è¿™ä¸¤ä¸ªï¼Œç»“æœç›¸å½“ä¸ä¸€æ ·



findallæ–¹æ³•ï¼ˆå…¨æŸ¥ï¼Œå†…å®¹å…¨éƒ¨åˆ†å‰²ï¼‰

æŸ¥è¯¢å…¨éƒ¨ç¬¦åˆçš„å†…å®¹ã€‚åªè¦ä¸­é—´ä¸è¿ç»­ï¼Œå³ä½¿æ˜¯ä¸€æ•´ä¸ªå­—ç¬¦ä¸²ï¼Œä¹Ÿä¼šåˆ†å‰²

ä¼šä»¥ä¸€ä¸ªåˆ—è¡¨åŒ…å«å…ƒç»„çš„æ–¹å¼è¿”å›[()]ï¼Œè¿™æ ·çš„æ–¹å¼å¯ä»¥ä½¿ç”¨forè¿”å›å€¼ for i in resultï¼Œiçš„è¿”å›æ˜¯ä¸€ä¸ªå…ƒç»„ï¼Œå…ƒç»„ä¹Ÿå¯ä»¥ç”¨foréå†ã€‚

åé¢ä¸€å®šä¼šæ¥è§¦jsonè¿”å›å€¼ï¼Œä¸€å®šä¼šæœ‰å­—å…¸ï¼Œæš‚æ—¶ä¸å»è€ƒè™‘



subæ–¹æ³•ï¼ˆå…¨æŸ¥ï¼Œå†…å®¹å…¨éƒ¨æ›¿æ¢ï¼Œæ›¿æ¢å†…å®¹ä¸¥æ ¼æŒ‰ç…§æ­£åˆ™è¡¨è¾¾å¼ï¼Œæ‹¬å·å†…ä¹ŸåŒ¹é…ï¼‰

æŠŠæ­£åˆ™è¡¨è¾¾å¼å†…å®¹æ›¿æ¢ï¼Œå¿…é¡»è¦ä¸‰ä¸ªå‚æ•°

```
result = re.sub('\d+','',content)
```

ä¸Šé¢å†…å®¹æ˜¯æŠŠcontentå†…å®¹ä¸­ï¼Œå¸¦æ•°å­—çš„ï¼Œæ›¿æ¢æˆç©º

???ä¸ºä»€ä¹ˆèƒ½åŒ¹é…åˆ°å…¨éƒ¨å†…å®¹

ç­”ï¼šå°±æ˜¯å¯ä»¥

\nå¥½åƒæ˜¯ä¸€ä¸ªå¾ˆç‰¹æ®Šçš„ä¸œè¥¿(æ¢è¡Œ)ï¼Œä»–å¥½åƒä¸èƒ½åŒ¹é…ï¼Œç”¨.*?éƒ½ä¸èƒ½åŒ¹é…ï¼Œéœ€è¦ä¹‹åç»™ä»–å»æ‰ï¼Œæ–¹æ³•ï¼š .strip()ï¼Œé»˜è®¤å»æ‰ç©ºæ ¼æ¢è¡Œ

subæ˜¯ä¸¥æ ¼æ›¿æ¢ï¼Œè¿ç©ºæ ¼éƒ½ç»™ç•™ä¸‹æ¥



compileæ–¹æ³•ï¼ˆå’Œsubæ›¿æ¢æ–¹æ³•ä¸€èµ·ç”¨ï¼‰

compile()å†…å†™çš„æ˜¯è¦ç”¨è¿™åˆ™è¡¨è¾¾å¼æ›¿æ¢çš„ä¸œè¥¿,sub()ï¼Œçš„ç¬¬ä¸€ä¸ªå¯ä»¥ç”¨compileæ›¿æ¢

```
pattern = re.compile('\d')
result = re.sub(pattern,'',content1)#ä¸¥æ ¼æ›¿æ¢ï¼Œè¿ç©ºæ ¼éƒ½ç•™ä¸‹æ¥
```

çœ‹èµ·æ¥å°±æ˜¯ä¸€ä¸ªå°è£…ï¼Œæ²¡æœ‰å¤šå¤§æ„ä¹‰ï¼Œçœ‹ä¸æ˜ç™½



httpxï¼ˆç½‘ç«™æœ‰ä¸ªåè®®ï¼Œhttp2.0ç”¨è¿™ä¸ªï¼Œå…¶ä»–requestsåº“å°±è¡Œï¼‰

httpxé»˜è®¤ä¸å¼€å¯http2ï¼Œéœ€è¦ä»£ç å¼€å¯

```
clinet = httpx.Client(http2=True)

response = clinet.get('https://spa16.scrape.center/')
```

å¯ä»¥ä»è¿”å›æ•°å€¼ç”¨.http_versionçœ‹å‡ºæ¥ä½¿ç”¨çš„åè®®ï¼Œä½†æ˜¯ä¸èƒ½å¯¹responseæŠ¥é”™çš„ä½¿ç”¨è¿™ä¸ª,å› ä¸ºä¼ å›æ¥çš„å€¼æœ¬èº«å°±æ˜¯é”™çš„



å¼‚æ­¥è¯·æ±‚

æ ¹æœ¬çœ‹ä¸æ‡‚(å®šä¹‰æ¨¡å—å‰é¢è¿˜åŠ ä¸€ä¸ªæ¨¡å—ï¼Œä¸çŸ¥é“å«ä¹‰,withå‰é¢åŠ ä¸€ä¸ªåŒ…ï¼Œä¸çŸ¥é“å«ä¹‰)

```
async def fetch(url): #æ ¹æœ¬çœ‹ä¸æ‡‚
    async with httpx.AsyncClient(http2=True) as clinet:
        response = await clinet.get(url)
        print(response.text)

if __name__ == '__main__':
    asyncio.get_event_loop().run_until_complete(fetch('https://www.httpbin.org/get'))
```

dir(åŒ…åå­—),å¯ä»¥ä¼ å›åŒ…åŒ…å«çš„æ–¹æ³•



demo1

åˆ†æ[Scrape | Movie](https://ssr1.scrape.center/)ç½‘é¡µ

1.å‘ç°ç½‘é¡µå†…å®¹ä½¿ç”¨el-rowåŒ…å«ä¸€ä¸ª

2.ç…§ç‰‡ä½¿ç”¨ä¸€ä¸ªé“¾æ¥ï¼Œé“¾è¿‡å»å¯ä»¥ç›´æ¥æ‰“å¼€ç½‘é¡µ

3.ç½‘é¡µæœ‰ä¸ªdetailè¯¦æƒ…ç•Œé¢ï¼Œåœ¨åŸå…ˆurlåŸºç¡€ä¸ŠåŠ /detail/æ•°å­— å°±èƒ½è®¿é—®

4.åˆ—è¡¨æ˜¯ä½¿ç”¨ul liå½¢å¼è®¿é—®çš„ /page/æ•°å­— å³å¯

çˆ¬å–ç½‘é¡µç½‘å€ï¼š

å…ˆç”¨forï¼ŒæŒ¨ä¸ªå¾—åˆ°åˆ—è¡¨çš„urlï¼›å†è¿›å…¥è¿™ä¸ªåˆ—è¡¨ç½‘é¡µï¼Œè·å–è¿™ä¸ªç½‘é¡µhtmlï¼Œç„¶ååˆ†ç¦»å‡ºæ¥è¶…é“¾æ¥ä¸­è¯¦æƒ…ç•Œé¢çš„urlï¼Œé“¾æ¥åˆ°æ ¹urlä¸Šã€‚

æˆ‘ä½¿ç”¨loggingæ–¹å¼æ‰“å°ç»“æœ,loggingéœ€è¦å…ˆå®šä¹‰æ‰“å°æ ¼å¼

```
logging.basicConfig(level=logging.INFO,format='%(asctime)s - %(levelname)s: %(message)s')
```

ä½¿ç”¨logging.infoæ‰“å°

```
logging.info('scraping %s...',url)
```

ç”¨try...expect...è®©ç¨‹åºå¥ç¡•ä¸€ç‚¹

tryæ˜¯æ‰§è¡Œç¨‹åºï¼Œexpectæ˜¯æ‰§è¡Œç¨‹åºæœ‰ä»€ä¹ˆé”™è¯¯ï¼Œä¼šè¿›å…¥åˆ°ä»–è¿™é‡Œ

```
requests.RequestException #åŒ…æ‹¬å¥½å¤šrequestsçš„é”™è¯¯
```

[Python3ï¼šRequestsæ¨¡å—çš„å¼‚å¸¸å€¼å¤„ç†RequestException_requestexceptionç”¨æ³•python-CSDNåšå®¢](https://blog.csdn.net/qq_40984952/article/details/105044771)

```
try:
    response = requests.get(url)
    if response.status_code == 200:
        return response.text
    else:
        logging.error('get invaild status code %s while scraping %s',response.status_code,url) 
except requests.RequestException: #æ‰€æœ‰å…¶ä»–ç±»å‹é”™è¯¯
    logging.error('error occured while scraping %s',url,exc_info=True)
```

å…¶ä¸­exc_infoè¯´æ˜¯æ‰“å°é”™è¯¯å †æ ˆä¿¡æ¯ï¼Œæˆ‘ä¹Ÿä¸æ‡‚

yield:è¿”å›ä¸€ä¸ªä¸œè¥¿ï¼Œå’Œreturnä¸€æ ·

å¯ä»¥ç”¨nextï¼Œlistæ‰“å°ï¼Œä½†æ˜¯ä¸ä¸€æ ·è¿™ä¸¤ä¸ª

```
for item in items:
    detail_url = urljoin(base_url, item)
    # print(detail_url)
    logging.info('get detail url %s',detail_url)
    yield detail_url #è¿”å›ä¸€ä¸ªæ•°å€¼
```

ç”¨nextå¥½åƒåªæ‰“å°ç¬¬ä¸€ä¸ªï¼Œç”¨listæ‰“å°å…¨éƒ¨ã€‚å°±åƒåœ¨forä¸­ï¼ŒæŠŠè¿”å›ä¸œè¥¿å…¨éƒ¨å­˜åœ¨ä¸€ä¸ªåœ°æ–¹ï¼Œnextè®¿é—®ç¬¬ä¸€ä¸ªï¼Œlistè®¿é—®å…¨éƒ¨

```
logging.info('detail urls %s',list(detail_urls)) #listä¸next
```

***å…³é”®ç‚¹ï¼šhtmlçš„æ­£åˆ™è¡¨è¾¾å¼è·å–ï¼Œæ˜¯æ ¹æ®è¿”å›æ¥çš„å€¼ç¡®å®šçš„ï¼Œè€Œä¸æ˜¯æ ¹æ®ç½‘é¡µæ¥çš„***



Xpathä¸­çš„etreeæ¨¡å—

[è§£æåº“xpathé«˜çº§ä½¿ç”¨ï¼ˆè¶…å…¨ï¼‰ - çŸ¥ä¹ (zhihu.com)](https://zhuanlan.zhihu.com/p/134126265)

æ˜¯æŠŠæ–‡æœ¬è½¬ä¸ºå¯ä»¥ä½¿ç”¨çš„æ–‡æœ¬ï¼Œå¥½åƒä»€ä¹ˆæ–‡æœ¬éƒ½å¯ä»¥

```
html = etree.HTML(text)
result = etree.tostring(html) #æ˜¯byteç±»å‹
print(result.decode("utf-8")) #.decodeæ˜¯æŠŠbyteè½¬ä¸ºå­—ç¬¦
```

htmlæŠŠæ–‡æœ¬åˆå§‹åŒ–ï¼Œæ„é€ ä¸€ä¸ªå¯ä»¥è§£æçš„å¯¹è±¡ï¼ˆçœ‹ä¸æ‡‚å«ä¹‰ï¼‰

resultç”¨tostringæŠŠæ–‡æœ¬ä¿®æ­£ä¸ºhtmlä»£ç ï¼Œä½†æ˜¯æ˜¯byteç±»å‹

.decode("utf-8")æŠŠbyteè½¬ä¸ºå­—ç¬¦ä¸²

æˆ‘æ„Ÿè§‰å°±æ˜¯å°†æ–‡æœ¬åŠ äº†ä¸€ä¸ªhtml,bodyæ ‡ç­¾ï¼Œå¥½åƒå•¥ä¹Ÿæ²¡å¹²

è¡¥äº†ï¼Œåœ¨è¾“å‡ºä¸‹é¢</li></ul>

```
html = etree.parse('./test.html',etree.HTMLParser())
```

è¿™æ ·è§£ææ–‡ä»¶.test.htmlï¼Œå¥½åƒæ˜¯æ„é€ ä¸€ä¸ªè§£æå¯¹è±¡ï¼Œä½†æ˜¯ç»“æœæœ‰è½¬ä¹‰å­—ç¬¦&#13æ„æ€æ˜¯å›è½¦,ä¹Ÿä¸çŸ¥é“æ€ä¹ˆå»æ‰



parse åˆ†æé¡µé¢å«æœ‰çš„å†…å®¹ï¼Œç»“æœä»¥æ•°ç»„è¿”å›å‡ºæ¥

å…ˆæŠŠæ–‡ä»¶å†…å®¹è½¬ä¸ºä¸€ä¸ªå¯ä»¥è§£æå¯¹è±¡ï¼Œç„¶ååœ¨åŒxpathæŠŠè¦å–çš„ä¸œè¥¿å†™å‡ºæ¥

```
html = etree.parse('./test.html',etree.HTMLParser())
result = html.xpath('//li')
print(result[0])
```

è¿™é‡Œæ˜¯åŒ¹é…æ‰€æœ‰lièŠ‚ç‚¹

//æ˜¯åŒ¹é…æ‰€æœ‰è¿™ä¸ªèŠ‚ç‚¹

ä½†æ˜¯ä¸æ˜ç™½è¿”å›å†…å®¹çš„å«ä¹‰

<Element li at 0x1882fba7480>

```
<div>
    <ul>
        <li class="item-0"><a href="link1.html">first item</a></li>
        <li class="item-1"><a href="link2.html">second item</a></li>
        <li class="item-inactive"><a href="link3.html">third item</a></li>
        <li class="item-1"><a href="link4.html">fourth item</a></li>
        <li class="item-0"><a href="link5.html">fifth item</a>
    </ul>
</div>
```

```
result = html.xpath('//li/a')
```

è·å–liçš„ç›´æ¥aèŠ‚ç‚¹ï¼Œè€Œä¸”æ˜¯å…¨éƒ¨å†…å®¹ã€‚å½“æŠŠliæ”¹ä¸ºulï¼Œå°±è·å–ä¸åˆ°äº†ï¼Œæ˜¯å› ä¸º/è·å–çš„æ˜¯å­èŠ‚ç‚¹

```
result = html.xpath('//li//a')
```

è·å–liçš„æ‰€æœ‰å­å­™èŠ‚ç‚¹aã€‚è¿™æ—¶æŠŠliæ¢ä¸ºulï¼Œå°±èƒ½å…¨éƒ¨è·å¾—äº†ã€‚